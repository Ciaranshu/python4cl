{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for Linguists module 1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to module 1.4. In this module, we will start calculating statistics using real corpus. \n",
    "\n",
    "Let's first refresh your memory on ngrams and probabilities by completing the following quiz:\n",
    "\n",
    "## Pre-module quiz\n",
    "\n",
    "Given the sequence 'aabbdab', what is *P*(b|a)?\n",
    "\n",
    "A. 1/2\n",
    "\n",
    "B. 1/3\n",
    "\n",
    "C. 2/3\n",
    "\n",
    "D. 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct answer is C. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For tokenization of a sentence\n",
    "# Create a Tokenizer with the default settings for English\n",
    "# including punctuation rules and exceptions\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "nlp = English() \n",
    "tokenizer = nlp.Defaults.create_tokenizer(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Processing the corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the Shakespeare corpus. The relative path to the corpus file is ../../corpora/shakespeare (.. indicates the parent directory). \n",
    "Let's first load the corpus by using the open function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('../../corpora/Shakespeare','r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We declared the variable f to open the Shakespeare file. Open takes 2 arguments, the path to the file that we want to open and a string that represents the kinds of permission or operation we want to do on the file. Here 'r' refers to the permission of 'read-only'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first import spac for tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Tokenizer with the default settings for English\n",
    "# including punctuation rules and exceptions\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "nlp = English() \n",
    "tokenizer = nlp.Defaults.create_tokenizer(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a for loop to process each line of the file and store the processed lines as tokenized word lists into another variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_processed=[] # a list to store the processed lines\n",
    "for line in f:\n",
    "    #for each line, we do:\n",
    "    #1. remove control characters like \\t \\r \\n\n",
    "    line=line.strip()\n",
    "    #2. skip the empty lines\n",
    "    if line=='':\n",
    "        continue\n",
    "    else: \n",
    "        #3. tokenize the sentence into word list:\n",
    "        tokens =[str(tok) for tok in tokenizer(line)]# tokens are now a list of words for the current line\n",
    "        f_processed.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's loop over the word lists in f_processed to create a vocabulary dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab={}# create a vocabulary dictionary where key is the word and value is the count\n",
    "for line in f_processed:\n",
    "    for word in line:\n",
    "        if word in vocab:\n",
    "            vocab[word]+=1 # update the count for an existing word\n",
    "        else:\n",
    "            vocab[word]=1 # initilize the count for a new word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice quiz 1:\n",
    "What is the count of the word 'book' in the corpus?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['book']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caluating Type-token ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate type count first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32864\n"
     ]
    }
   ],
   "source": [
    "type_count=len(vocab.keys())# the number of types is just the length of the key list\n",
    "print (type_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's caculate token count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1133363\n"
     ]
    }
   ],
   "source": [
    "# Let's create a loop to aggregate the token counts in the vocabulary:\n",
    "token_count=0\n",
    "for word in vocab:\n",
    "    token_count+=vocab[word]\n",
    "print (token_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.028996888022637054\n"
     ]
    }
   ],
   "source": [
    "#Let's calculate the type-token ratio:\n",
    "ttr=type_count/token_count\n",
    "print (ttr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could wrap the calculation up into a function that takes in vocab dictionary and outputs the ttr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttr_cal(vocab):\n",
    "    type_count=len(vocab.keys())\n",
    "    token_count=0\n",
    "    for word in vocab:\n",
    "        token_count+=vocab[word]\n",
    "    ttr=type_count/token_count\n",
    "    return ttr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.028996888022637054\n"
     ]
    }
   ],
   "source": [
    "print (ttr_cal(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting a frequency distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first import matplotlib for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can sort the words to get the top-100 frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn=100\n",
    "vocab_sorted=sorted(vocab.items(),key=lambda x: x[1],reverse=True)[:topn]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loop through the sorted vocabulary to get words and counts for plotting the graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]\n",
    "counts=[]\n",
    "for w_c in vocab_sorted:\n",
    "    w=w_c[0]\n",
    "    words.append(w)\n",
    "    count=w_c[1]\n",
    "    counts.append(count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could now plot a histogram using the words and counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,5)) #figure size\n",
    "plt.bar(words,counts) #plot the historgram\n",
    "plt.xticks(rotation=90) # rotate the x label\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice quiz 2:\n",
    "Try changing topn and observe what are the properties of the top-frequent words?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bigram is a sequence of adjacent two words. Let's create a nested dictionary to store the bigrams. They key will be each bigram and the value will be counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first loop through the lines in f_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_dict={}\n",
    "for line in f_processed:\n",
    "    #insert start <start> and end <end> token\n",
    "    line=['<start>']+line+['<end>']\n",
    "    for i,w in enumerate(line):\n",
    "        w_first=w\n",
    "        if i+1<len(line): #not the end of the line\n",
    "            w_second=line[i+1]\n",
    "            bigram=(w_first,w_second) #a tuple to represent bigram\n",
    "            if bigram not in bigram_dict:\n",
    "                bigram_dict[bigram]=1\n",
    "            else:\n",
    "                bigram_dict[bigram]+=1\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice quiz 3:\n",
    "What is the count of the bigram 'thank you'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_dict[('thank','you')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language modelling\n",
    "\n",
    "Language modelling is a fundamental task in computational lingustics where the aim is to predict the probablity of a sequence of tokens occuring. We will consider tokens to be words in this exercise, but they can be many other things depending on the application (perhaps characters, utterances, phonemes, _etc_). \n",
    "\n",
    "Formally, we want to estimate the probablity $P(w_{1},\\ldots ,w_{m})$ of an $m$-length sequence, using some given corpus.\n",
    "\n",
    "There are many techniques for language modelling; we will consider here a very simple approach called $n$-gram models. These models make the assumption that the probability of a word only depends on the previous $n-1$ context words in the sequence. If $n=1$, we call this a *unigram* model, if $n=2$, it's a *bigram* model etc.\n",
    "\n",
    "So for example, given a sequence of words: *'to be or not to'* what is the probablity the next word will be *'be'*?  In $n$-gram models, this is calculated using *conditional probablity*: $P(`be'\\mid \\text{`to be or not to'})$ where we estimate the probablity of the entire sequence using the probablity chain rule (_i.e_. multiplying the conditional probabilities of the sequence):\n",
    "\n",
    "\n",
    "$$P(w_{1},\\ldots ,w_{m})=\\prod _{{i=1}}^{m}P(w_{i}\\mid w_{1},\\ldots ,w_{{i-1}})\\approx \\prod _{{i=1}}^{m}P(w_{i}\\mid w_{{i-(n-1)}},\\ldots ,w_{{i-1}})$$\n",
    "\n",
    "We can estimate the conditional probility from our training corpus by simply counting:\n",
    "\n",
    "$$P(w_{i}\\mid w_{{i-(n-1)}},\\ldots ,w_{{i-1}})={\\frac  {{\\mathrm  {count}}(w_{{i-(n-1)}},\\ldots ,w_{{i-1}},w_{i})}{{\\mathrm  {count}}(w_{{i-(n-1)}},\\ldots ,w_{{i-1}})}}$$\n",
    "\n",
    "### Unigram language model\n",
    "Let's start by building the most basic $n$-gram model, a unigram model where the conditional probablity for each word is simply the probablity of the word occuring in the corpus data: it does not dependent on any of the previous words in the sequence.\n",
    "\n",
    "We can start by defining a function called *unigram_prob* which calculates the probability of a unigram given as an input parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_prob(word):\n",
    "    return float(vocab[word]/token_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this by calculating the probability of the word \"horse\" occuring in the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00021175916277485677"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_prob(\"horse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice quiz 4:\n",
    "Calculate the probability and the effect of capitalisation on the definite article. Try \"The\" vs \"THE\" vs \"the\", and note how much the probability differs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0035452013167890607"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_prob(\"The\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00010323259185274268"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_prob(\"THE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020503580935675506"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_prob(\"the\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the probability of a sequence (a sentence, paragraph, _etc_.) occurring, we use the chain rule of probability by multiplying the unigram probability of individual words. So lets calculate the probability of the sequence: *'To be, or not to be, that is the question:'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.408562399710954e-30"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_prob(\"To\") * unigram_prob(\"be\") * unigram_prob(\"or\")* unigram_prob(\"not\") * unigram_prob(\"to\") * unigram_prob(\"be\") * unigram_prob(\",\") * unigram_prob(\"that\") * unigram_prob(\"is\") * unigram_prob(\"the\") * unigram_prob(\"the\") * unigram_prob(\"question\") * unigram_prob(\":\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probablity value of our example sequence is a very small number! In fact, it is so small that it's about the same probability of picking the same ant thrice at random from all the ants on the planet!\n",
    "\n",
    "What happens if we continue to add further words to this sequence?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-probability\n",
    "\n",
    "Eventually the probability values will get so tiny that computers will not be able to represent them correctly in memory; this is known as an *underflow error*.  It will not require much more text to get an underflow error: a simple paragraph using our unigram model will result in one! \n",
    "\n",
    "Fortunately, there is a very simple way to avoid this: we can use log-probability instead of regular probability. To do so, we simply use the log function in our unigram_prob function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def unigram_prob(word):\n",
    "    return math.log(float(vocab[word]/token_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try calculacting the log-probability for the word \"horse\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.460060953704279"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_prob(\"horse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the log-probability of an entire sequence, we simply add the individual log-probablity values of individual unigrams instead of multiplying them. \n",
    "\n",
    "Let's write a function that calculates the log-probability of a given text sequence (as a single string). The function must tokenize the input string correctly before performing the calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_prob_for_sequence(tokens):\n",
    "    return sum([unigram_prob(tok) for tok in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now calculate the log-probablity of our example sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-66.11605999786988"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"To be, or not to be, that is the question:\"\n",
    "example_sequence = [str(tok) for tok in tokenizer(text)]\n",
    "unigram_prob_for_sequence(example_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice quiz 5:\n",
    "Calculate the log-probability of the sentence: *'A horse, a horse! My kingdom for a horse!'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-74.21539318177221"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"A horse, a horse! My kingdom for a horse!\"\n",
    "tokens = [str(tok) for tok in tokenizer(text)]\n",
    "unigram_prob_for_sequence(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram language model\n",
    "\n",
    "Unlike the unigram language model above, a bigram language model uses the context history. It uses conditional probability to estimate the probability of a word occuring relative to the occurance of its predecessor in the sequence:\n",
    "\n",
    "$$P(w_{i}\\mid w_{i-1})={\\frac  {{\\mathrm  {count}}(w_{i-1},w_{i})}{{\\mathrm  {count}}(w_{i-1})}}$$\n",
    "\n",
    "Let's implement a bigram_prob function that calculates the bigram conditional probability for a single token:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_prob(w1, w2):\n",
    "    return math.log(float(bigram_dict[(w1,w2)]/vocab[w1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this by calculating the conditional log-probability for the bigram \"to be\", i.e., the log-probability of the word \"be\" given the word \"to\" appearing before it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.0051406123266844"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_prob(\"to\", \"be\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can write a function to calculate the log-probability for a sequence of text using our bigram language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_prob_for_sequence(tokens):\n",
    "    return sum([bigram_prob(w1,w2) for w1,w2 in zip(tokens, tokens[1:])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this function to calculate the log probability of our example sequence, and compare it to the unigram language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-66.11605999786988"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_prob_for_sequence(example_sequence) # log-probability using unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-49.81572109265195"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_prob_for_sequence(example_sequence) # log-probability using bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to note that the log-probability value using the bigram model is substantially larger (the sequence is much likelier to occur). Is this perhaps because the bigram language model takes the context history into account whereas a unigram language model does not?\n",
    "\n",
    "We discuss how to correctly evaluate language models in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice quiz 6:\n",
    "Calculate and compare the unigram and bigram log-probabilities of the sentence: *'Double, double, toil and trouble; fire burns, and cauldron bubble.'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-107.52272746936798"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Double, double, toil and trouble; fire burns, and cauldron bubble.\"\n",
    "tokens = [str(tok) for tok in tokenizer(text)]\n",
    "unigram_prob_for_sequence(tokens) # log-probability using unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-65.18214590870909"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_prob_for_sequence(tokens) # log-probability using bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating language models\n",
    "\n",
    "Language models are evaluated using *perplexity* ($P$), a measure of how well a probability model predicts a given sample (e.g. text sequences).\n",
    "\n",
    "Perplexity is defined as $P = 2^{{h(s)}}$ where $h$ is the information entropy per word for a given input $s$. $h(s)$ can be calculated as follows:\n",
    "\n",
    "$$h(s)=\\frac{-1}{|s|}\\sum _{w \\in s}\\log _{2}P(w)$$\n",
    "\n",
    "Here, $s$ is some sample text and $|s|$ is the number of tokens in $s$.\n",
    "\n",
    "The value of perplexity can be thought of as the number of choices the model needs to make on average per token of the input sequence. The lower the perplexity score, the better the language model is since the model has fewer choices on average for the input sequence. \n",
    "\n",
    "Let's implement a simple function to calculate the perplexity, taking as input the log-probability (calculated by a language model) and the length of a sequence (in number of tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(log_prob, length):\n",
    "    H =  - (log_prob/ math.log(2)) / length  #change of log-base from base 10 to base 2, then normalize by length\n",
    "    return math.pow(2,H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the perplexity of both language models by simply calling the respective functions, and feed the results to the perplexity function above along with the length of the example sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.1537652847171"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(bigram_prob_for_sequence(example_sequence),len(example_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161.7174649447508"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(unigram_prob_for_sequence(example_sequence),len(example_sequence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice quiz 7:\n",
    "Which of the two models has a lower perplexity?  measure the perplixity of both models using the example text sentences from previous quizes. \n",
    "\n",
    "Can you find a text string where the unigram model has a lower perplexity than the bigram model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "371px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
