{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "module_2.3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJewFf6DDO2C"
      },
      "source": [
        "# Python for Computational Linguists 2.3: Part-of-speech Tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzmRkFiXkQnB"
      },
      "source": [
        "Welcome to module 2.3. In this module, we will use the Python library `NLTK` to erxplore part-of-speech (POS) tagging, an important early NLP application.\n",
        "By the end of the module, you should be able to\n",
        "- understand the definition of POS tagging, tagset and tagged corpora with examples.\n",
        "- use data structure `dictionary` to store various information for POS tagging.\n",
        "- know how to split the data into training and test set, and the evaluation metrics for POS tagging.\n",
        "- build different types of tagging models in NLTK. \n",
        "- get an overview of Viterbi algorithm for POS tagging decoding/inference.\n",
        "\n",
        "\n",
        "Let's start with a pre-module quiz to review POS tagging."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgODhOF1kQnC"
      },
      "source": [
        "## ❓ Pre-module quiz\n",
        "\n",
        "Which descriptions are true about POS tagging?\n",
        "\n",
        "A. POS tagging is a task of text classification (similar to document classification), where we assign a single label to the input text sequence.\n",
        "\n",
        "B. POS tagging is a task of sequence labelling, where we assign a label to each word/token of the input text sequence.\n",
        "\n",
        "C. We can use POS tagging to disambiguate certain words/tokens.\n",
        "\n",
        "D. We can use POS tagging to solve syntactic ambiguity, e.g. PP atachment.\n",
        "\n",
        "<hr>    <!-- please remember this! -->\n",
        "<details>\n",
        "  <summary>Click <b>here</b> to see the answer.</summary>\n",
        "  <p>B, C.</p>\n",
        "  <p>POS tagging is the task of assigning a word category (POS tag) to each word from the input sequence, so it is a sequence labelling task.</p>\n",
        "  <p>POS tagging can be used to address lexical ambiguity such as heterophones: CONtent (noun) and conTent (adjective), but for higher level syntactic ambiguity, we need parsing to solve it.</p>\n",
        "</details> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GgJipxvDO2L"
      },
      "source": [
        "## What is POS tagging?\n",
        "For each word in context, we can assign a **lexical category**, such as noun, verbs, adjectives, etc.\n",
        "These categories are often referred to as a word's part-of-speech tag or POS tag.\n",
        "The set of all POS tags is called a **tagset**, and the activity of assigning these tags to words is referred to as **part-of-speech tagging** or simply as **POS tagging**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5rNkKVYDO2M"
      },
      "source": [
        "### Why do we want to do POS tagging?\n",
        "As the POS tag of a word will give a large amount of information about this word and its neighbours, POS tagging can help understanding better texts, beneficial to many dowstream NLP tasks such as:\n",
        "\n",
        "1. Disambiguating word senses. Consider the following example for the heterophone *content*:\n",
        "    - There was very little **CONtent** to the essay.\n",
        "    - The sleepy pug puppy was very **conTENT**.\n",
        "  \n",
        "  or homonyms:\n",
        "  - It is wrong to **object** to this **object**.\n",
        "  - I must **present** the **present** on his birthday.\n",
        "  - The insurance for the **invalid** was **invalid**.\n",
        "\n",
        "2. Mitigating the issue of data sparsity. \n",
        "    - Label named entities like people, places or organizations as part of information extraction systems. In the following example, both *Chase Manhattan* and *J.P. Morgan* should be detected as proper nouns:\n",
        "        - **Chase Manhattan** and its merger partner **J.P. Morgan**.\n",
        "    \n",
        "    - Deal with out-of-vocabulary (OOV) words such as neologisms or acronyms in the social media: \n",
        "        - @username its #awesome u gonna ♥ it Chk out our cooool project on some_url + RT it.\n",
        "\n",
        "\n",
        "More generally, being able to automatically perform POS tagging will help reduce the laborious human effort required to parse a sentence, and it will be the main goal of this module, which is to build such an automatic model/tagger."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUZJ0zk7kQnD"
      },
      "source": [
        "### POS Tagset\n",
        "\n",
        "There are multiple POS tagsets available, and their design often depends on both linguistic and practical considerations, but will generally include both syntactic and punctuation categories. We might, for instance, wish to distinguish between 1st, 2nd or 3rd person present tense verbs. \n",
        "Note that increasing the size of the tagset does not necessarily result in making the task of tagging more complicated: this depends on whether the tags that are added can generally be assigned unambiguously or not.\n",
        "\n",
        "Very commonly used tagsets include the 87-tag [Brown set](http://www.helsinki.fi/varieng/CoRD/corpora/BROWN/tags.html), 45-tag [Penn Treebank set](https://www.aclweb.org/anthology/J93-2004.pdf), the 61-tag [CLAWS 5 (C5)](http://ucrel.lancs.ac.uk/claws5tags.html), and the 17-tag [Universal POS tagset](https://universaldependencies.org/u/pos/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfssuaVNkQnD"
      },
      "source": [
        "> **<h3>❓ Quiz</h3>**\n",
        "\n",
        "Use the 17-tag [Universal POS tagset](https://universaldependencies.org/u/pos/) to tag the ambiguous words in square brackets:\n",
        "\n",
        "1. There was very little [**content**] to the essay.\n",
        "2. The sleepy pug puppy was very [**content**].\n",
        "3. It is wrong to **object** to this [**object**].\n",
        "4. I must [**present**] the [**present**] on his birthday.\n",
        "5. The insurance for the [**invalid**] was [**invalid**].\n",
        "6. They [**refuse**] to permit us to obtain the [**refuse**] permit.\n",
        "7. [**Chase Manhattan**] and its merger partner [**J.P. Morgan**].\n",
        "8. @username its [**#awesome**] u gonna [**♥**] it Chk out our cooool project on some_url [**+**] [**RT**] it.\n",
        "\n",
        "<hr>    <!-- please remember this! -->\n",
        "<details>\n",
        "  <summary>Click <b>here</b> to see the answer.</summary>\n",
        "  <p>1. NOUN</p>\n",
        "  <p>2. ADJ</p>\n",
        "  <p>3. VERB NOUN</p>\n",
        "  <p>4. VERB NOUN</p>\n",
        "  <p>5. NOUN ADJ</p>\n",
        "  <p>6. VERB NOUN</p>\n",
        "  <p>7. PROPN PROPN PROPN PROPN</p>\n",
        "  <p>8. ADJ VERB CCONJ VERB</p>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIuXAYe_DO2U"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1De39wDDO2W"
      },
      "source": [
        "Before building our own POS tagging model, we are going to use the NLTK library to load some existing taggers to perform POS tagging, and some tagged corpora will be introduced for further training and evaluations of our models.\n",
        "First let's import the [NLTK](https://www.nltk.org/) library and download some necessary resources."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6S2SodjDO2X"
      },
      "source": [
        "import nltk\n",
        "nltk.__version__\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('brown')\n",
        "nltk.download('treebank')\n",
        "nltk.download('tagsets')\n",
        "nltk.download('gutenberg')\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6rVLyc-DO2i"
      },
      "source": [
        "Given the input text, we need to first tokenize it to separate words from other tokens such as punctuations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZLMREilDO2j"
      },
      "source": [
        "text = \"I like this module and NLTK's model very very much!\"\n",
        "print(text)\n",
        "tokenized_text = nltk.word_tokenize(text)\n",
        "print(tokenized_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMsX-kdtDO2q"
      },
      "source": [
        "We can see that the tokenized text is a list where each element is a tokenized token. \n",
        "\n",
        "Now let's tag the tokenized text using a pre-built tagger in NLTK."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ynlt2jeDO2r"
      },
      "source": [
        "tagged_text = nltk.pos_tag(tokenized_text)\n",
        "print(tagged_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYmkVSXXDO2z"
      },
      "source": [
        "The returned tagged text is a list, where each element is a tuple. For each tuple, the first element is the token, and the second element is its corresponding POS tag in Penn Treebank tag set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3tWv279DO20"
      },
      "source": [
        "NLTK provides documentation for each tag, which can be queried using the tag, e.g., `nltk.help.upenn_tagset('PRP')`, or a regular expression, e.g., `nltk.help.upenn_brown_tagset('NN.*')`. Some corpora have README files with tagset documentation; see `nltk.name.readme()`, substituting in the name of the corpus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "1_cqoTAsDO21"
      },
      "source": [
        "> **<h3>❓ Quiz</h3>**\n",
        "\n",
        "Use the current tagger to tag the same example sentences in the previous quize to see if the key words (heterophone, homonym, named entity and neologism) are correctly tagged. Identify wrong tags.\n",
        "\n",
        "1. There was very little **content** to the essay.\n",
        "2. The sleepy pug puppy was very **content**.\n",
        "3. It is wrong to **object** to this **object**.\n",
        "4. I must **present** the **present** on his birthday.\n",
        "5. The insurance for the **invalid** was **invalid**.\n",
        "6. They **refuse** to permit us to obtain the **refuse** permit.\n",
        "7. **Chase Manhattan** and its merger partner **J.P. Morgan**.\n",
        "8. @username its **#awesome** u gonna **♥** it Chk out our cooool project on some_url **+** **RT** it.\n",
        "\n",
        "<hr>    <!-- please remember this! -->\n",
        "<details>\n",
        "  <summary>Click <b>here</b> to see the answer.</summary>\n",
        "   <p><pre><code>\n",
        "   texts = ['There was very little content to the essay.',\n",
        "         'The sleepy pug puppy was very content.',\n",
        "         'It is wrong to object to this object.',\n",
        "         'I must present the present on his birthday.',\n",
        "         'The insurance for the invalid was invalid.',\n",
        "         'They refuse to permit us to obtain the refuse permit.',\n",
        "         'Chase Manhattan and its merger partner J.P. Morgan.',\n",
        "         '@username its #awesome u gonna ♥ it Chk out our cooool project on some_url + RT it.']\n",
        "    for text in texts:\n",
        "        tokenized_text = nltk.word_tokenize(text)\n",
        "        tagged_text = nltk.pos_tag(tokenized_text)\n",
        "        print(tagged_text)\n",
        "    </code></pre></p> \n",
        "  <p>1. NN</p>\n",
        "  <p>2. JJ</p>\n",
        "  <p>3. VB NN</p>\n",
        "  <p>4. VB NN</p>\n",
        "  <p>5. NN JJ</p>\n",
        "  <p>6. VBP NN</p>\n",
        "  <p>7. NNP NNP NNP NNP</p>\n",
        "  <p>8. # JJ (#awesome is split to # awesome) VB NNP(wrong, should be CC) NNP(wrong, should be VB)</p>\n",
        "  <hr>\n",
        "  <p>Follow-up question: what will happen if we convert all letters to lower case?</p>\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzs8c8g1DO25"
      },
      "source": [
        "### Connection with Text Classification\n",
        "\n",
        "As we have seen in previous modules, text classification is the task where we assign a single label to the whole sequence of text, e.g. document. \n",
        "POS tagging can be also viewd similarly. Instead of assigning a label on the document level, we assign a label to each word or token. This type of task is usually called **sequence labeling**, and POS tagging is one of the most important tasks of sequence labelling in NLP."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBKhxCS4DO26"
      },
      "source": [
        "## Tagged corpora\n",
        "POS taggers using machine learning techniques generally require annotated data to train on.\n",
        "For all tagging models, including those that do not require any training data like regex- or rule-based models, an annotated evaluation dataset is also required to measure the performance of these models by comparing the model outputs with the gold standard annotations.\n",
        "\n",
        "Tagged corpora, generally annotated by an human expert, have the form similar to the following:\n",
        "\n",
        "```\n",
        "The/AT grand/JJ jury/NN commented/VBD on/IN a/AT number/NN of/IN other/AP topics/NNS ,/, AMONG/IN them/PPO the/AT Atlanta/NP and/CC Fulton/NP-tl County/NN-tl purchasing/VBG departments/NNS which/WDT it/PPS said/VBD ``/`` ARE/BER well/QL operated/VBN and/CC follow/VB generally/RB accepted/VBN practices/NNS which/WDT inure/VB to/IN the/AT best/JJT interest/NN of/IN both/ABX governments/NNS ''/'' ./.\n",
        "```\n",
        "Different datasets might have different tagsets and forms, but each word (token) in sentences will be generally accompanied by a POS tag to form the pair **word/tag**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reStt-rwDO27"
      },
      "source": [
        "Let's explore the [Penn Treebank Corpus](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.9.8216&rep=rep1&type=pdf) and the [Brown Corpus](https://en.wikipedia.org/wiki/Brown_Corpus) annotated with POS tags.\n",
        "Both corpora are already included in NLTK with POS tags, and we can get the full text by calling `tagged_words()` or `tagged_sents()` when the corpus is also segmented into sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkbiwdJvDO3C"
      },
      "source": [
        "# read Penn Treebank Corpus\n",
        "print(nltk.corpus.treebank.tagged_words())\n",
        "print(nltk.corpus.treebank.tagged_sents())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUODO8NMDO28"
      },
      "source": [
        "# read Brown Corpus\n",
        "print(nltk.corpus.brown.tagged_words())\n",
        "print(nltk.corpus.brown.tagged_sents())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOwsxj-5DO3N"
      },
      "source": [
        "Did you notice that the tags used in the two corpora are different? As we mentioned before, they are indeed using different tagsets, and to investigate what each tag category means, we can check both tagsets: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt9h5VacDO3Y"
      },
      "source": [
        "# Penn Treebank tagset\n",
        "nltk.help.upenn_tagset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-9yjw0ADO3P"
      },
      "source": [
        "# Brown tagset\n",
        "nltk.help.brown_tagset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVNIdOZ3kQnM"
      },
      "source": [
        "Please pause and have a look at the both tagsets along with the definition of each tag. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uj9JK_okDO3j"
      },
      "source": [
        "Taking the Penn Treebank Corpus as an example, we can explore the corpus further by counting how many times a tag appears in the corpus, and create a distribution of tags.\n",
        "Let's use NLTK's `FreqDict` to store the frequency of each tag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_eA3zroDO3q"
      },
      "source": [
        "tag_fd = nltk.FreqDist(tag for (word, tag) in nltk.corpus.treebank.tagged_words())\n",
        "tag_fd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Hl5Pt4EDO32"
      },
      "source": [
        "We can find the most and least frequent POS tag by sorting the dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay1TuyjsDO34"
      },
      "source": [
        "tag_list = sorted(tag_fd.items(), key=lambda kv: kv[1], reverse=True)\n",
        "print(tag_list[0])\n",
        "print(tag_list[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCf4So3UDO4B"
      },
      "source": [
        "We can also plot the curve of the POS tag frequency distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ytBRfCHDO4B"
      },
      "source": [
        "tag_fd.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arHQRd8hDO4W"
      },
      "source": [
        "Finally, let’s look for words that are highly ambiguous as to their POS tag. Understanding why such words are tagged as they are in each context can help us clarify the distinctions among the tags.\n",
        "\n",
        "Note that the items being counted in the frequency distribution are word-tag pairs, we can then use the NLTK's `ConditionalFreqDist`.\n",
        "We treat the word as a condition and the tag as an event, and initialize a conditional frequency distribution with a list of condition-event pairs. This lets us see a frequency-ordered list of tags given a word:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X81wWfpLDO4X"
      },
      "source": [
        "data = nltk.ConditionalFreqDist((word, tag) for (word, tag) in nltk.corpus.treebank.tagged_words())\n",
        "print(data.conditions()[0])\n",
        "data['The']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQfIr67jDO4e"
      },
      "source": [
        "We can print first 10 words along with their POS tags when the word has more than 3 tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGgJZspkDO4e"
      },
      "source": [
        "idx = 0\n",
        "for word in data.conditions():\n",
        "    if len(data[word]) > 3:\n",
        "        tags = list(data[word].keys())\n",
        "        print (word, ' '.join(tags))\n",
        "        idx += 1\n",
        "        if idx >= 10:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCcVirkrDO4k"
      },
      "source": [
        "> **<h3>❓ Quiz</h3>**\n",
        "\n",
        "For Brown Corpus, repeat the same process, i.e. plotting the distribution of the tagset and finding the most and least frequent tag. \n",
        "What kinds of words occur in the noun, adjective, adverb category? \n",
        "Explore the POS tag ditribution of ambiguous words mentioned before, e.g. *content* and *present*. Do they support our observations?\n",
        "\n",
        "\n",
        "\n",
        "<hr>    <!-- please remember this! -->\n",
        "<details>\n",
        "  <summary>Click <b>here</b> to see the answer.</summary>\n",
        "   <p><pre><code>\n",
        "    # build dictionary where tag is the condition\n",
        "    tag_word_freq = nltk.ConditionalFreqDist((tag, word) for (word, tag) in nltk.corpus.brown.tagged_words())\n",
        "    # an example for NN (singular noun)\n",
        "    # printing the most frequent ten words along with their frequency\n",
        "    idx = 0\n",
        "    for word, freq in sorted(tag_word_freq['NN'].items(), key=lambda x: x[1], reverse=True):\n",
        "        print(word, freq)\n",
        "        idx += 1\n",
        "        if idx == 9:\n",
        "            break     \n",
        "    # explore the tag distribution of ambiguious words, taking `content` as an example     \n",
        "    word_tag_freq = nltk.ConditionalFreqDist((word, tag) for (word, tag) in nltk.corpus.brown.tagged_words())\n",
        "    print('Tag distribution of the word CONTENT:')\n",
        "    word_tag_freq['content'].plot()\n",
        "    </code></pre></p> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHuFNJ_oDO4n"
      },
      "source": [
        "### POS tag n-grams\n",
        "So far we have been working with only a single POS tag in text sequence, i.e. the unigram. \n",
        "However, we should be aware that each POS tag in text sequence often depends on its previous/following tags.\n",
        "For example, nouns can appear after determiners and adjectives, and can be the subject or object of the verb.\n",
        "Therefore, we can look at some n-gram sequences of POS tags such as tag bi-grams.\n",
        "\n",
        "Let's build a frequency dictionary of tag bi-grams for the Penn Treebank Corpus using `bi-grams`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J-rbYO-DO4o"
      },
      "source": [
        "tag_bigram_list = list(nltk.bigrams(nltk.corpus.treebank.tagged_words()))\n",
        "tag_bigram_fd = nltk.FreqDist((a[1], b[1]) for (a, b) in tag_bigram_list if b[1])\n",
        "tag_bigram_fd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piNIlFnxDO4u"
      },
      "source": [
        "We can see that compared to unigram tag frequency dictionary, bigram dictionary has many more entries, each with smaller frequency. \n",
        "It can potentiall cause the data sparsity problmen as we will encounter later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKICrzikDO4w"
      },
      "source": [
        "To validate our intuitions that nouns often occur after the determiners and adjectives, we can investigate the distribution of tag bi-gram **(X, NN)** where **X** refers to any possible tag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMQa50ZoDO4x"
      },
      "source": [
        "nn_bigram_fd = nltk.FreqDist({k: v for k, v in tag_bigram_fd.items() if k[1] == 'NN'})\n",
        "sorted_nn_bigram_list = sorted(nn_bigram_fd.items(), key=lambda kv: kv[1], reverse=True)\n",
        "print(sorted_nn_bigram_list[:20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ49CtaaDO45"
      },
      "source": [
        "We can see that the two most frequent tags with **(X, NN)** are indeed **DT** (determiner) and **JJ** (adjective) according to the Penn Treebank Corpus tagset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKEX55KGkQnT"
      },
      "source": [
        "> **<h3>❓ Quiz</h3>**\n",
        "\n",
        "Repeat the same process, plot the distribution of tag appearing after adjective in Brown Corpus. \n",
        "\n",
        "\n",
        "<hr>    <!-- please remember this! -->\n",
        "<details>\n",
        "  <summary>Click <b>here</b> to see the answer.</summary>\n",
        "   <p><pre><code>\n",
        "    tag_bigram_list = list(nltk.bigrams(nltk.corpus.brown.tagged_words()))\n",
        "    tag_bigram_fd = nltk.FreqDist((a[1], b[1]) for (a, b) in tag_bigram_list if b[1])\n",
        "    jj_x_bigram_fd = nltk.FreqDist({k: v for k, v in tag_bigram_fd.items() if k[0] == 'JJ'})\n",
        "    jj_x_bigram_fd.plot()\n",
        "    </code></pre></p> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A93RhIh2DO47"
      },
      "source": [
        "## Mapping of properties using Python dictionaries\n",
        "As we have seen, a tagged word of the form **(word, tag)** is an association between a word and a POS tag. \n",
        "Once we start doing POS tagging, we will be using such structures extensively.\n",
        "For example, we want to get the tag list of a given word **(word, tag list)**, or the frequency of a given tag **(tag, freq)**.\n",
        "We can think of this process as mapping from a certain property to another, and the most natural way to store mappings in Python uses the so-called `dictionary` data type, which we have encountered in module 1 and previous part of this module. \n",
        "\n",
        "We look at dictionaries and see how they can represent a variety of language information. \n",
        "For example, recall the frequency dictionary we used previously, which maps from a POS tag to its frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_QqJciyDO48"
      },
      "source": [
        "tag_fd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjblRyhkDO5P"
      },
      "source": [
        "If we want to create a dictionary of the form **(word, tags)**, what types would be for the key and value of the dictionary?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPwzLATqDO5S"
      },
      "source": [
        "word2tags = {'present': 'V', 'object': 'N'}\n",
        "for k, v in word2tags.items():\n",
        "    print('{}: {}'.format(k, word2tags[k]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEZTe3sZDO5W"
      },
      "source": [
        "Here we use word as the key and its corresponding tag as the value.\n",
        "We use the `string` type for tag, which can be problematic, as both words *present* and *object* can be noun and verb, so if we want to change a tag of *present*, the original tag will be overwritten."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3OuZwO9DO5Y"
      },
      "source": [
        "word = 'present'\n",
        "print('{}: {}'.format(word, word2tags[word]))\n",
        "word2tags['present'] = 'N'\n",
        "print('{}: {}'.format(word, word2tags[word]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jngBzF-_DO5d"
      },
      "source": [
        "A better way is to use the mapping **(word (string), tags (list))** for the dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTSrYWuHDO5e"
      },
      "source": [
        "word2tags = {'present': ['V', 'N'], 'object': ['V', 'N']}\n",
        "for k, v in word2tags.items():\n",
        "    print('{}: {}'.format(k, word2tags[k]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DL6PySYSDO5j"
      },
      "source": [
        "And if we want to further add a new tag to the word, we can simply `append` it to the tag list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Gqs2ahODO5l"
      },
      "source": [
        "word = 'present'\n",
        "print('{}: {}'.format(word, word2tags[word]))\n",
        "word2tags[word].append('ADJ')\n",
        "print('{}: {}'.format(word, word2tags[word]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUZC5Nq6DO5p"
      },
      "source": [
        "#### Default dictionaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEk5Sgs9DO5q"
      },
      "source": [
        "If we try to access a key that is not in a dictionary, we get an error. \n",
        "However, it’s often useful if a dictionary can automatically create an entry for this new key and give it a default value, such as zero or the empty list.\n",
        "Both **NLTK** and **Python** provide us with the `defaultdict`, a more advanced dictionary, where we can supply a parameter which can be used to create the default value, e.g., int, float, str, list, dict, tuple.\n",
        "For simplicity, we will stick to the `defaultdict` of NLTK, and for that of Python you can refer to the [link](https://docs.python.org/3/library/collections.html#collections.defaultdict)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fllBE2rmkQnX"
      },
      "source": [
        "Here we build a **(tag, freq)** dictionary, and assign 0 frequency to a new tag *UNK*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kaLPKVfDO5r"
      },
      "source": [
        "tag_fd_def = nltk.defaultdict(int, tag_fd)\n",
        "print(tag_fd_def['NN'])\n",
        "print(tag_fd_def['UNK'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSlrVJOQkQnY"
      },
      "source": [
        "Here we build a **(word, tags)** dictionary, and assign a tag list with the most frequent tag **NN** inside it to a new word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b8doyuIDO5w"
      },
      "source": [
        "word2tags_def = nltk.defaultdict(lambda: ['NN'], word2tags)\n",
        "print(word2tags_def['present'])\n",
        "print(word2tags_def['a_new_word'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkPsNCLRDO5z"
      },
      "source": [
        "> **<h3>❓ Quiz</h3>**\n",
        "\n",
        "1. In NLP, one of the preprocessing steps is to replace low-frequency words with a special \"out of vocabulary\" token, *UNK*, with the help of a default dictionary. Preprocess Brown corpus: keep the most frequent *n* words, and map the rest words to UNK.\n",
        "2. Create a POS unigram for the Brown Corpus of the mapping **(word, tag_list)**.\n",
        "\n",
        "<hr>    <!-- please remember this! -->\n",
        "<details>\n",
        "  <summary>Click <b>here</b> to see the answer.</summary>\n",
        "   <p><pre><code>\n",
        "    brown_word_freq = nltk.defaultdict(int)\n",
        "    brown_word_taglist = nltk.defaultdict(list)\n",
        "    # the cut-off number n\n",
        "    n = 100\n",
        "    for word, tag in nltk.corpus.brown.tagged_words():\n",
        "        brown_word_freq[word] += 1\n",
        "        brown_word_taglist[word].append(tag)\n",
        "    for i, (word, freq) in enumerate(sorted(brown_word_freq.items(), key=lambda x: x[1], reverse=True)):\n",
        "        if i >= 100:\n",
        "            brown_word_freq['UNK'] += freq\n",
        "            del brown_word_freq[word]\n",
        "    </code></pre></p> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T71k7AOBDO55"
      },
      "source": [
        "### POS tag n-grams for tagging\n",
        "We can use default dictionaries with complex keys and values to build tag n-grams for tagging.\n",
        "\n",
        "Taking bi-gram as an example, we want to store the frequency of tag **t2**, which depends on the tag **t1** of its previous word, and the current word **w2**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxM-LjDWDO56"
      },
      "source": [
        "# create a nested default dictionary, where the value is another default dictionary whose default value is int (0)\n",
        "pos = nltk.defaultdict(lambda: nltk.defaultdict(int))\n",
        "# create bigrams of (word, tag) pair\n",
        "for ((w1, t1), (w2, t2)) in nltk.bigrams(nltk.corpus.treebank.tagged_words()):\n",
        "    pos[(t1, w2)][t2] += 1\n",
        "print(pos[('DT', 'right')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBUzcFILDO5_"
      },
      "source": [
        "Each time through the loop we updated our `pos` entry for **(t1, w2)**, a tag and its following word. \n",
        "When we look up an item in `pos` we must specify a compound key , and we get back a dictionary object. \n",
        "A POS tagger could use such information to decide that the word *right*, when preceded by a determiner, should be tagged as one of the tags in *NN*, *JJ*, and *RB*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5k41padDO6A"
      },
      "source": [
        "## Automatic Tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdyqqkNcDO6B"
      },
      "source": [
        "We will explore various ways to automatically perform POS tagging. We will see that the tag of a word depends on the word and its context within a *sentence*. \n",
        "For this reason, we will be working with data at the level of (tagged) sentences rather than words. \n",
        "\n",
        "We’ll begin by loading the Penn Treebank data we will be using."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONunhs7PDO6B"
      },
      "source": [
        "penn_tagged_sents = nltk.corpus.treebank.tagged_sents()\n",
        "penn_sents = nltk.corpus.treebank.sents()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIlSUz_uDO6E"
      },
      "source": [
        "### Data Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znPR6DKVDO6F"
      },
      "source": [
        "As we mentioned earlier, for most machine learning POS taggers, a split of the original dataset into the *training* set and *test* set is necessary.\n",
        "Training and testing a model on a single dataset can easily lead to the problem of [overfitting](https://en.wikipedia.org/wiki/Overfitting), as a tagger that simply memorized its training data and made no attempt to construct a general model would get a perfect score, but would be useless for tagging new text. \n",
        "Therefore, another held-out test set is used after training the model with training set to evaluate the generalizability of the model.\n",
        "\n",
        "In this section, we split the data, training on 90% and testing on the remaining 10%, and this proportion may vary depending on the task and data size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pq2hvscwDO6H"
      },
      "source": [
        "train_prop = 0.9\n",
        "size = int(len(penn_tagged_sents) * train_prop)\n",
        "train_tagged_sents = penn_tagged_sents[:size]\n",
        "test_tagged_sents = penn_tagged_sents[size:]\n",
        "train_sents = penn_sents[:size]\n",
        "test_sents = penn_sents[size:]\n",
        "print('Training sents: {} {}'.format(len(train_sents), len(train_tagged_sents)))\n",
        "print('Test sents: {} {}'.format(len(test_sents), len(test_tagged_sents)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAf_c5rfDO6Q"
      },
      "source": [
        "Now we split the original annotated dataset into a training and test set. we will evaluate **ALL** taggers on the test set, and use training data for taggers that require data to train on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq1xHxy7DO6S"
      },
      "source": [
        "> **<h3>❓ Quiz</h3>**\n",
        "\n",
        "1. Create the tag distribution plot of both *training* and *test* set of Penn Treebank Corpus, and compare them with the plot of the whole corpus. What difference can you see?\n",
        "2. Calculate the out-of-vocabulary (OOV) rate between the training and test sets:\n",
        "    - report the number of tokens and token types in the 90% training set;\n",
        "    - report the number of tokens and token types in the 10% test set;\n",
        "    - report the TEST token OOV rate and token type OOV rate, i.e. percentage of words in test that are not present in training. \n",
        "\n",
        "<hr>    <!-- please remember this! -->\n",
        "<details>\n",
        "  <summary>Click <b>here</b> to see the answer.</summary>\n",
        "   <p><pre><code>\n",
        "   # full data\n",
        "    tag_fd = nltk.FreqDist(tag for sent in penn_tagged_sents for (word, tag) in sent)\n",
        "    tag_fd.plot()\n",
        "    # training data\n",
        "    train_tag_fd = nltk.FreqDist(tag for sent in train_tagged_sents for (word, tag) in sent)\n",
        "    train_tag_fd.plot()\n",
        "    # test data\n",
        "    test_tag_fd = nltk.FreqDist(tag for sent in test_tagged_sents for (word, tag) in sent)\n",
        "    test_tag_fd.plot()\n",
        "    # number of tokens and token types in training data\n",
        "    train_token_freq = nltk.defaultdict(int)\n",
        "    for sent in train_tagged_sents: \n",
        "        for (word, tag) in sent:\n",
        "            train_token_freq[word] += 1\n",
        "    print(f'Training: {sum(train_token_freq.values())}, {len(train_token_freq.keys())}')\n",
        "    # number of tokens and token types in test data\n",
        "    test_token_freq = nltk.defaultdict(int)\n",
        "    for sent in test_tagged_sents: \n",
        "        for (word, tag) in sent:\n",
        "            test_token_freq[word] += 1\n",
        "    print(f'Test: {sum(test_token_freq.values())}, {len(test_token_freq.keys())}')\n",
        "    # OOV rate\n",
        "    OOV_token = .0\n",
        "    OOV_token_type = .0\n",
        "    for t_token, t_freq in test_token_freq.items():\n",
        "        # test token not exists in train data\n",
        "        if t_token not in train_token_freq:\n",
        "            OOV_token += t_freq\n",
        "            OOV_token_type += 1\n",
        "    print(f'Test OOV rate: {OOV_token / sum(test_token_freq.values()) * 100:.2f}%, {OOV_token_type / len(test_token_freq.keys()) * 100:.2f}%')\n",
        "    </code></pre></p> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBaoeH0nDO6U"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8DdBzBZDO6U"
      },
      "source": [
        "Evaluation is another core part of NLP.\n",
        "When evaluating our models on test set annotated by human experts, what numbers are we going to report? An intuitive one is the *accuracy* comparing the gold standard test set tags and the predicted tags produced by the model, i.e. the percentage of correct tags the model has predicted.\n",
        "\n",
        "Recall the term *presicion*, *recall* and *F1-score* for 2-class classification, which we have encountered in lectures.\n",
        "You can check [here](https://en.wikipedia.org/wiki/Precision_and_recall) for a quick recap.\n",
        "Precision is calculated as $\\frac{\\textrm{true positive}}{\\textrm{true positive} + \\textrm{false positive}}$ and recall as $\\frac{\\textrm{true positive}}{\\textrm{true positive + false negative}}$.\n",
        "\n",
        "It is still applicable in POS tagging, where we can have these number for EACH POS tag category (NN v.s. non NN). We can achieve this by building a *confusion matrix* of the outputs.\n",
        "\n",
        "Let's use the tagger in the very beginning of the section and create such confusion matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avsdYKNeDO6U"
      },
      "source": [
        "gold_test_tags = [tag for test_tagged_sent in test_tagged_sents for (word, tag) in test_tagged_sent]\n",
        "pred_test_tags = [tag for test_sent in test_sents for (word, tag) in nltk.pos_tag(test_sent)]\n",
        "print(nltk.ConfusionMatrix(gold_test_tags, pred_test_tags).pretty_format())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Andl53zVDO6X"
      },
      "source": [
        "As we can see, the row values indicate the POS tags given by reference (gold standard test set), and the column tags are from the model output.\n",
        "\n",
        "In order to calculate the metrics we mentioned earlier, let's first read the whole matrix in:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_iXYufyDO6Z"
      },
      "source": [
        "cm = nltk.ConfusionMatrix(gold_test_tags, pred_test_tags)\n",
        "cm_matrix = np.array(cm._confusion)\n",
        "print(cm_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ceg0Y4mQDO6f"
      },
      "source": [
        "The total number of tags are just the sum of the matrix value, where you can verify from the previous quiz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eF8yAI8DO6h"
      },
      "source": [
        "total_tags = np.sum(cm_matrix)\n",
        "total_tags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnA2NbNqDO6m"
      },
      "source": [
        "*Accuracy* is simply the ratio between the correct tags (sum of the diagnoal value called *trace*) and total tag number."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpT3mijBDO6m"
      },
      "source": [
        "acc = np.trace(cm_matrix) / total_tags\n",
        "acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLR3CjKJDO6q"
      },
      "source": [
        "Taking **NN** as an example, we want to calualte the *precision*, *recall* and *F1-score*.\n",
        "\n",
        "First we need to calculate true positive, false positive and false negative.\n",
        "True positive is simply the entry where both row and column are **NN**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sERKpF1dDO6r"
      },
      "source": [
        "nn_idx = cm._indices['NN']\n",
        "tp = cm_matrix[nn_idx][nn_idx]\n",
        "tp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYamHpGWDO6v"
      },
      "source": [
        "False positive is the sum of *NN* column (all model predicted *NN*) values exluding true positive (correctly predicted *NN*). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HptD6yRpDO6v"
      },
      "source": [
        "fp = sum(cm_matrix[:, nn_idx]) - tp\n",
        "fp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-ixUhdRDO6y"
      },
      "source": [
        "Similarly, False negative is the sum of *NN* row (all gold/real *NN*) values exluding true positive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9anYdmXDO6y"
      },
      "source": [
        "fn = sum(cm_matrix[nn_idx, :]) - tp\n",
        "fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84GxTQeTDO62"
      },
      "source": [
        "The precision, recall and F1-score can be caclculated accordingly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S56TbzMWDO63"
      },
      "source": [
        "precision = tp / (tp + fp)\n",
        "recall = tp / (tp + fn)\n",
        "f1 = 2 * precision * recall / (precision + recall)\n",
        "print(precision, recall, f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXq2EdxtDO68"
      },
      "source": [
        "> **<h3>💻 Try it yourself!</h3>**\n",
        "\n",
        "Calculate the three metrics for POS tags you are interested in with the same tagger, and complete the table below.\n",
        "\n",
        "| POS           | Precision     | Recall  | F1-score \n",
        "| ------------- |---------------|---------|----------\n",
        "| NN      | 85.9 | 93.1 | 89.4 \n",
        "| JJ      |      |      |      \n",
        "| Add tag here   |      |      |      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-fTGxzsDO69"
      },
      "source": [
        "### Default tagger\n",
        "The simplest possible tagger assigns the same tag to each token. This may seem to be a rather banal step, but it establishes an important baseline for tagger performance. \n",
        "In order to get the best result, we tag each word with the most likely tag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5foR3yhNDO69"
      },
      "source": [
        "nltk.FreqDist(gold_test_tags).max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25jgzTOaDO7B"
      },
      "source": [
        "Now we can create a tagger that tags everything as **NN**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N-ARB82DO7C"
      },
      "source": [
        "default_tagger = nltk.DefaultTagger('NN')\n",
        "default_preds = [(word, tag) for test_sent in test_sents for (word, tag) in default_tagger.tag(test_sent)]\n",
        "default_preds[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfZvjK7r1FJG"
      },
      "source": [
        "The accuracy of this tagger is"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hsMtyVuDO7H"
      },
      "source": [
        "default_pred_test_tags = [tag for (word, tag) in default_preds]\n",
        "default_cm = nltk.ConfusionMatrix(gold_test_tags, default_pred_test_tags)\n",
        "default_cm_matrix = np.array(default_cm._confusion)\n",
        "acc = np.trace(default_cm_matrix) / np.sum(default_cm_matrix)\n",
        "acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8yoUd18DO7M"
      },
      "source": [
        "Alternatively, we can directly calculate accuracy with `evaluate()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtTPYChjDO7O"
      },
      "source": [
        "acc_sys = default_tagger.evaluate(test_tagged_sents)\n",
        "acc_sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-m9nU5CWDO7T"
      },
      "source": [
        "> **<h3>💻 Try it yourself!</h3>**\n",
        "\n",
        "Calculate the three metrics for POS tags you are interested in with the **default** tagger, and complete the table below.\n",
        "\n",
        "| POS           | Precision     | Recall  | F1-score \n",
        "| ------------- |---------------|---------|----------\n",
        "| NN            |  |  |  \n",
        "| JJ             |      |      |      \n",
        "| Add tag here  |      |      |      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fogy2wPBDO7V"
      },
      "source": [
        "### The most frequent 100 unigram tagger\n",
        "A lot of high-frequency words do not have the **NN** tag. \n",
        "Let’s find the 100 most frequent words and store their most likely tags. We can then use this information as the\n",
        "model for a *lookup tagger*, which is an NLTK UnigramTagger."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvRyNfEGDO7V"
      },
      "source": [
        "# create a FreqDist of word unigram from training corpus\n",
        "fd = nltk.FreqDist([word for train_tagged_sent in train_tagged_sents for (word, tag) in train_tagged_sent])\n",
        "# get the 100 most frequent unigram word \n",
        "most_freq_words = list(fd.keys())[:100]\n",
        "# create a ConditionalFreqDist associating the word and POS tags\n",
        "cfd = nltk.ConditionalFreqDist([(word, tag) for train_tagged_sent in train_tagged_sents for (word, tag) in train_tagged_sent])\n",
        "# get the most likely tag for each word\n",
        "likely_tags = dict((word, cfd[word].max()) for word in most_freq_words)\n",
        "print(likely_tags)\n",
        "baseline_tagger = nltk.UnigramTagger(model=likely_tags)\n",
        "baseline_tagger.evaluate(test_tagged_sents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSfoloybkQno"
      },
      "source": [
        "Let's try to tag some sentence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6udj09iIkQnp"
      },
      "source": [
        "baseline_tagger.tag(train_sents[6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zagVvYHkQnp"
      },
      "source": [
        "We can see that many words have been assigned a tag of **None**, because they were not among the 100 most frequent words. In these cases we would like to assign the default tag of **NN**. In other words, we want to use the lookup table first, and if it is unable to assign a tag, then use the default tagger, a process known as **backoff**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9_G42JskQnq"
      },
      "source": [
        "baseline_tagger = nltk.UnigramTagger(model=likely_tags, \n",
        "                                     backoff=nltk.DefaultTagger('NN'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-vpFf0IkQnq"
      },
      "source": [
        "Now the lookup tagger will only store word-tag pairs for words other than nouns, and whenever it cannot assign a tag to a word, it will invoke the default tagger."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuMfQplgkQnq"
      },
      "source": [
        "baseline_tagger.evaluate(test_tagged_sents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPLx2bJmkQnr"
      },
      "source": [
        "And tagging the same sentence will give us different results now, where **None** is substituted by **NN**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I4sdkeEkQnr"
      },
      "source": [
        "baseline_tagger.tag(train_sents[6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcrKsu89kQnr"
      },
      "source": [
        "> **<h3>💻 Try it yourself!</h3>**\n",
        "\n",
        "Calculate the three metrics for POS tags you are interested in with the **lookup** tagger with **backoff**, and complete the table below.\n",
        "\n",
        "| POS           | Precision     | Recall  | F1-score \n",
        "| ------------- |---------------|---------|----------\n",
        "| NN            |  |  |  \n",
        "| JJ             |      |      |      \n",
        "| Add tag here  |      |      |      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPzM2xsrkQnr"
      },
      "source": [
        "## N-gram tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVA09oMQkQns"
      },
      "source": [
        "The previous 100 most frequent lookup tagger is essentially a **unigram** tagger, where we consider only the current token, in isolation from any larger context. \n",
        "Given such a model, the best we can do is to tag each word with its a *priori* most likely tag learned from the training data. \n",
        "This means we would tag a word such as *wind* with the same tag, regardless of whether it appears in the context *the wind* or *to wind*.\n",
        "\n",
        "An n-gram tagger is a generalization of a unigram tagger whose context is the current word together with the POS tags of the $n-1$ preceding tokens, as shown below. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr8vjwmkkQns"
      },
      "source": [
        "![ngram_tagger](https://github.com/cambridgeltl/python4cl/blob/module_2.3/module_2/module_2.3/ngram_tagger.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNntnkxjkQns"
      },
      "source": [
        "Here the tag to be chosen, $t_n$, is circled, and the context is shaded in grey. \n",
        "In the example of an n-gram tagger, we have $n=2$, i.e. a **tri-gram** tagger; that is, the model will pick the most likely $t_n$ given the 2 preceding tags in addition to the current word.\n",
        "\n",
        "Recall again the unigram tagger, we have $n=0$, where it doesn't consider any previous word tags, but only the current word token."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5qUpgyOkQns"
      },
      "source": [
        "### Bi-gram tagger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI1nUlrakQnt"
      },
      "source": [
        "Ideally, when we have larger $n$, the model will learn more specific situations which can be potentially helpful for our tagging.\n",
        "However, given the limited training data, the model will also learn either too specific or irrelevant information (noise) which cannot generalize well to the test data.\n",
        "We call this data sparsity problem.\n",
        "\n",
        "Consider the following example:\n",
        "```\n",
        "I/PRP really/RB like/VBP to/TO **wind** ...\n",
        "\n",
        "I/PRP like/VBP to/TO **wind** ...\n",
        "```\n",
        "Now if we want to decide the tag of the word **wind**, for a tri-gram tagger, both sentences will give us the same information: (VPB, TO, wind).\n",
        "However, if we use a 4-gram tagger, the first sentence will give us (RB, VBP, TO, wind) whereas the second one will give us (PRP, VBP, TO, wind).\n",
        "It will\n",
        "1. reduce the signal of (VPB, TO, wind) which is useful for tagging, as (RB, VBP, TO, wind) and (PRP, VBP, TO, wind) will be counted separately once where in trigram tagger (VPB, TO, wind) will be counted twice, which is the main cause of data sparsity.\n",
        "2. learn irrelevant information from (RB, VBP, TO, wind) and (PRP, VBP, TO, wind) as the first tag really doesn't help us better in tagging in general.\n",
        "\n",
        "As a consequence, there is always a trade-off between the accuracy and the coverage of our results, which is closely related to the concept of overfitting, where for a certain amount of training data, we do not want our model to be too complex to perform well on the training data, but cannot generalize on real-world unseen data.\n",
        "\n",
        "Generally, in NLP practice, a **bi-gram** tagger is sufficient to obtain a good test performance for the POS tagging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usMjiosykQnt"
      },
      "source": [
        "# train the tagger with training data\n",
        "t2 = nltk.BigramTagger(train_tagged_sents)\n",
        "# evaluate the tagger on the test data\n",
        "t2.evaluate(test_tagged_sents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eABrvTr2kQnt"
      },
      "source": [
        "t2.tag(train_sents[6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpYXWZ2skQnu"
      },
      "source": [
        "t2.tag(test_sents[6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD3YeRTUkQnu"
      },
      "source": [
        "We can see that the the default bi-gram tagger can tag sentences in the training data pretty well, but fails to tag the test data sentence and yields a lot of **None** tags.\n",
        "It is still eseentially a look-up tagger, and when the tagger encounters a new combination of (previous_tag, current_word), it will output **None** as the predicted tag and immediately propagate to the following predictions with (None, current_word) tuples, as the tagger has never seen the tag **None** in training data.\n",
        "\n",
        "There are two ways to remedy for that:\n",
        "- As seen previously, we can use **backoff** to combine bi-gram tagger with unigram and default tagger.\n",
        "- Use a more sophisticated bi-gram tagging model, which we will see later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLZZaNsokQny"
      },
      "source": [
        "> **<h3>❓ Quiz</h3>**\n",
        "\n",
        "Build a bi-gram look-up tagger with back-off, where it first falls back to the unigram tagger, and then the default tagger with *NN* as the default tag.\n",
        "\n",
        "<hr>    <!-- please remember this! -->\n",
        "<details>\n",
        "  <summary>Click <b>here</b> to see the answer.</summary>\n",
        "   <p><pre><code>\n",
        "    t0 = nltk.DefaultTagger('NN')\n",
        "    t1 = nltk.UnigramTagger(train_tagged_sents, backoff=t0)\n",
        "    t2 = nltk.BigramTagger(train_tagged_sents, backoff=t1)\n",
        "    t2.evaluate(test_tagged_sents)\n",
        "    </code></pre></p> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpEs9z58kQny"
      },
      "source": [
        "> **<h3>💻 Try it yourself!</h3>**\n",
        "\n",
        "Calculate the three metrics for POS tags you are interested in with the **bi-gram lookup** tagger with **backoff**, and complete the table below.\n",
        "\n",
        "| POS           | Precision     | Recall  | F1-score \n",
        "| ------------- |---------------|---------|----------\n",
        "| NN            |  |  |  \n",
        "| JJ             |      |      |      \n",
        "| Add tag here  |      |      |      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTEZjLoNkQnz"
      },
      "source": [
        "### Hidden Markov Model (HMM) Bi-gram Tagger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HfrtNjWkQnz"
      },
      "source": [
        "The bad performance of the bi-gram look-up tagger is mainly caused by \n",
        "1. The direct use of the bi-gram information $p(t_i | w_i, t_{i-1})$ without considering internal structures between tags and words; \n",
        "2. Greedy decoding at each step not taking the previous tagged results into account."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2HsWvybkQnz"
      },
      "source": [
        "Here we introduce a more sophisticated bi-gram tagger called hidden Markov model (HMM) tagger.\n",
        "In general, given a sequence of texts with length $n$ $w_1^n$, e.g. sentence, an HMM tagger tries to find the tag sequence $\\hat{t}_1^n$ with the highest probability:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\hat{t}_1^n &= \\arg\\max_{t_1^n} p(t_1^n | w_1^n)\\\\ \n",
        "&= \\arg\\max_{t_1^n} \\frac{p(w_1^n | t_1^n)p(t_1^n)}{p(w_1^n)}\\qquad\\textrm{Bayes rule}\\\\\n",
        "&= \\arg\\max_{t_1^n} p(w_1^n | t_1^n)p(t_1^n)\\qquad\\textrm{Because $p(w_1^n)$ does not effect the selection of $\\hat{t}_1^n$.}\n",
        "\\end{aligned}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQAxtHTHkQn0"
      },
      "source": [
        "where\n",
        "$$\n",
        "p(w_1^n | t_1^n) = p(w_1, w_2, ..., w_n | t_1, t_2, ..., t_n) \\approx \\sum_{i=1}^n p(w_i | t_i) \\\\\n",
        "$$\n",
        "with the assumption that tag $t_i$ is the **hidden** variable that only determines the observation word $w_i$, and"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONroTRgSkQn0"
      },
      "source": [
        "$$\n",
        "p(t_1^n) = p(t_1, t_2, ..., t_n) = \\underbrace{\\sum_{i=1}^n p(t_i | t_1, ... t_{i-1})}_\\textrm{chain rule} \\approx \\sum_{i=1}^n p(t_i | t_{i-1})\n",
        "$$\n",
        "assuming the first-order **Markov** process, corresponding to bi-gram tag, where each state (variable) is only dependent on the immediately previous state.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX-WO1B0kQn0"
      },
      "source": [
        "With the previous two assumptions, we can rewrite the equation for HMM bi-gram tagger:\n",
        "$$\n",
        "\\hat{t}_1^n \\approx \\arg\\max_{t_1^n} \\sum_{i=1}^n \\underbrace{p(w_i | t_i)}_\\textrm{emission}\\underbrace{p(t_i | t_{i-1})}_\\textrm{transition}\n",
        "$$\n",
        "where we have the emission probability $p(w_i | t_i) = \\frac{C(t_i, w_i)}{C(t_i)}$ and transition probability $p(t_i | t_{i-1}) = \\frac{C(t_{i-1}, t_i)}{C(t_i)}$ for each step $i$, and here $C(\\cdot)$ means the count or frequency for corresponding variables that we obtain from the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73w5_lyZkQn0"
      },
      "source": [
        "In practice we can use a [matrix](https://en.wikipedia.org/wiki/Matrix_(mathematics)) $A = a_{ij}$ to denote the transition probability from $t_i$ to $t_j$ and a dictionary B to store emission probability $p(w_i | t_i)$ = B[$t_i$][$w_i$]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDvGv4XjkQn1"
      },
      "source": [
        "We use HMM bi-gram tagger to address the problem 1 of the look-up tagger, and during decoding (equivalent to prediction/inference) we use **Viterbi algorithm** to address the problem 2 for greedy decoding.\n",
        "We show the algorithm of Viterbi algorithm from J&M 3 book, and please refer to the original book [link](http://web.stanford.edu/~jurafsky/slp3/8.pdf) for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLLwmwCMkQn1"
      },
      "source": [
        "The intuition behind the algorithm is that the best path of length $t$ ending in a particular tag must include the best path of length $t-1$ ending in the previous tag.\n",
        "Each step forward uses the probability of the pathway at the previous step, the conditional probability of the next tag given the current tag, and the probability of seeing a word given the current tag."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44n9sxAGkQn1"
      },
      "source": [
        "![viterbi](https://github.com/cambridgeltl/python4cl/blob/module_2.3/module_2/module_2.3/viterbi.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WN5mVo5gkQn2"
      },
      "source": [
        "Let's first create an HMM tagger and train it with training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZfosmowkQn2"
      },
      "source": [
        "hmm_tagger = nltk.HiddenMarkovModelTagger.train(train_tagged_sents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVNETRo_kQn2"
      },
      "source": [
        "Then we can try to tag some sentences with the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjk6O69CkQn3"
      },
      "source": [
        "hmm_tagger.test(test_tagged_sents[:2], verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "napGVFZwkQn3"
      },
      "source": [
        "We evaluate the HMM tagger on the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQJJSAW7kQn3"
      },
      "source": [
        "hmm_tagger.evaluate(test_tagged_sents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4S947xh6kQn3"
      },
      "source": [
        "Now let's visualize the viterbi algorithm with a revised HMM tagger (You don't have to understand the code here)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtD7kUuQkQn4"
      },
      "source": [
        "def _identity(labeled_symbols):\n",
        "    return labeled_symbols\n",
        "\n",
        "class RevisedHiddenMarkovModelTagger(nltk.HiddenMarkovModelTagger):\n",
        "    def __init__(self, symbols, states, transitions, outputs, priors, transform=_identity):\n",
        "        super(RevisedHiddenMarkovModelTagger, self).__init__(symbols, states, transitions, outputs, priors, transform=transform)\n",
        "    \n",
        "    def _best_path(self, unlabeled_sequence):\n",
        "        T = len(unlabeled_sequence)\n",
        "        N = len(self._states)\n",
        "        self._create_cache()\n",
        "        self._update_cache(unlabeled_sequence)\n",
        "        # P is the log prior probability tags (T)\n",
        "        # O is log omission probability (T, vocab_size)\n",
        "        # X is log transition probability (T, T)\n",
        "        # S is idx -> token dict (vocab_size)\n",
        "        P, O, X, S = self._cache\n",
        "        \n",
        "        # V is the log proability for tag path (T, N)\n",
        "        # B is the tag path (T, N)\n",
        "        V = np.zeros((T, N), np.float32)\n",
        "        B = -np.ones((T, N), np.int)\n",
        "        \n",
        "        # initialization, log(prior(t)) + log(p_o(w_1 | t))\n",
        "        V[0] = P + O[:, S[unlabeled_sequence[0]]]\n",
        "        # start from the second token of the sequence\n",
        "        for t in range(1, T):\n",
        "            # iterate over all possible tags \n",
        "            for j in range(N):\n",
        "                # log(p_previous_seq_end_in_any_tag) + log(p(tag_j | tag_any))\n",
        "                vs = V[t - 1, :] + X[:, j]\n",
        "                # pick the tag that maximizes vs: log(p_previous_seq_end_in_tag_best) + log(p(tag_j | tag_best))\n",
        "                best = np.argmax(vs)\n",
        "                # log(p_previous_seq_end_in_tag_best) + log(p(tag_j | tag_best)) + log(p(w_t | tag_j))\n",
        "                V[t, j] = vs[best] + O[j, S[unlabeled_sequence[t]]]\n",
        "                B[t, j] = best # previous tag index is `best`\n",
        "                \n",
        "        # get best seq, along with the last tag index `current`\n",
        "        current = np.argmax(V[T - 1, :])\n",
        "        sequence = [current]\n",
        "        # trace back tag sequence\n",
        "        for t in range(T - 1, 0, -1):\n",
        "            # get the previous tag index `last`\n",
        "            last = B[t, current]\n",
        "            sequence.append(last)\n",
        "            current = last\n",
        "\n",
        "        sequence.reverse()\n",
        "        # map the tag sequence id to the actual tag\n",
        "        return list(map(self._states.__getitem__, sequence)), V, B, O, X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ao2_MlZkQn4"
      },
      "source": [
        "revised_hmm_tagger = RevisedHiddenMarkovModelTagger.train(train_tagged_sents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JyIKw78kQn4"
      },
      "source": [
        "We now visualize a single test sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw6DnWJHkQn5"
      },
      "source": [
        "test_sent_idx = 6 # you can change the index to test different sentences\n",
        "print(test_sents[test_sent_idx])\n",
        "best_path, V, B, O, X = revised_hmm_tagger.best_path(test_sents[test_sent_idx])\n",
        "print(best_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhR8lWMRkQn5"
      },
      "source": [
        "# convert backpoint B to corresponding tag\n",
        "id2tag = {i: t for i, t in enumerate(revised_hmm_tagger._states)}\n",
        "id2tag[-1] = '<S>'\n",
        "tag2id = {v: k for k, v in id2tag.items()}\n",
        "f = np.vectorize(lambda x: id2tag[x])\n",
        "B_tag = f(B.T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoKELU3lkQn5"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "print(best_path)\n",
        "\n",
        "plt.figure(figsize = (20, 30))\n",
        "ax = sns.heatmap(V.T,\n",
        "                 cbar=False,\n",
        "                 annot=B_tag,\n",
        "                 annot_kws={'va':'bottom'},\n",
        "                 fmt=\"\")\n",
        "ax = sns.heatmap(V.T, \n",
        "                 cbar=False, \n",
        "                 annot=True,\n",
        "                 xticklabels=test_sents[test_sent_idx],\n",
        "                 yticklabels=revised_hmm_tagger._states,\n",
        "                 annot_kws={'va':'top'},\n",
        "                )\n",
        "for i, t in enumerate(best_path):\n",
        "    ax.add_patch(Rectangle((i, tag2id[t]), 1, 1, edgecolor='blue', fill=False, lw=3))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaBdyzAvkQn6"
      },
      "source": [
        "Here the rows represent all possible tags (all tags in the tagset), and the colums show each token of the sentence. The value of the heatmap is the log probability of the tagged setences ending with a specific tag in the previous step, and the blue box shows the selected tag for each step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNNeidbzkQn6"
      },
      "source": [
        "## ✍️ Final Assessment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHXX_pVRDO2F"
      },
      "source": [
        "1. Run the HMM bi-gram tagger trained on the **full** Penn Treebank on this made-up sentence \n",
        "```\n",
        "@Will WOOOHOO Will the New jPhone bOut 2night? Soexcited :)\n",
        "```\n",
        "Does the tagger get the correct answer?  Write down two challenges the tagger has incorrectly resolved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXAikSFmkQn7"
      },
      "source": [
        "2. For Brown Corpus, Write a program to find out:\n",
        "\n",
        "a. which word has the most POS tags and tag types in the corpus.\n",
        "\n",
        "b. what percentage of words in the corpus are ambiguous, i.e. have more than one POS tag."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuWsk3XWkQn8"
      },
      "source": [
        "3. Write a program to replace low frequency words (words with a frequency of 5 or less) with UNK in the **full** Penn Treebank corpus. \n",
        "What is the F-score of your bi-gram backoff tagger (fall back to unigram model, and then to the default tagger with `NN` as the default tag) on the Penn Treebank test set using the same train/test split previously? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dh4YV0TTkQn8"
      },
      "source": [
        "# Survey\n",
        "\n",
        "Please complete the [post-module survey](https://docs.google.com/forms/d/e/1FAIpQLSeLX1N344kBn8q9PTgg455lrzvVzzI5IW9itF4cT_WqeQKaFQ/viewform) when you are finished. Thank you!\n",
        "\n",
        "# Additional resources\n",
        "\n",
        "- Chapter 5 about part-of-speech tagging from the book [Natural Language Processing with Python](http://www.datascienceassn.org/sites/default/files/Natural%20Language%20Processing%20with%20Python.pdf).\n",
        "- [NLTK library documentation](https://www.nltk.org/).\n",
        "- Chapter 8 about part-of-speech tagging from the book [Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/8.pdf)."
      ]
    }
  ]
}